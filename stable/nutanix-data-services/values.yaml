# Default values for nutanix-dataservices-operator
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

manager:
  # -- Image Repository
  repository: 
  # -- Image tag
  # @default -- .Chart.AppVersion
  tag: 
  # -- Image digest
  digest: 
  # -- Image pull policy
  pullPolicy: Always

infraManager:
  # -- Image Repository
  repository: 
  # -- Image tag
  # @default -- .Chart.AppVersion
  tag: 
  # -- Image digest
  digest: 
  # -- Image pull policy
  pullPolicy: Always

kubeRbacProxy:
  # -- Image Repository
  repository: 
  # -- Image tag
  tag: 
  # -- Image digest
  digest: 

kubectl:
  # -- Image Repository
  repository: 
  # -- Image tag
  tag: 
  # -- Image digest
  digest: 
  # -- Image pull policy

# Set Values for NDK Metrics Monitoring using Prometheus
prometheus:
  # Requires Prometheus Operator CRDs
  enable: false
  # Set values for Prometheus serviceMonitor
  serviceMonitor:
    # Add Custom labels for serviceMonitor here
    customLabels: {}

# Set Values for Job Scheduler container
jobScheduler:
  # -- Image Repository
  repository: 
  # -- Image tag
  # @default -- .Chart.AppVersion
  tag: 
  # -- Image digest
  digest: 
  # -- Image pull policy
  pullPolicy: Always

# Set values for the nutanix-dataservices deployment
deployment:
  customLabels: { }
  # -- List of Kubernetes [`tolerations`](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/) to add to the Deployment.
  tolerations: [ ]
  # -- Kubernetes [`nodeSelector`](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector) to add to the Deployment.
  nodeSelector: { }
  # Set values for kube-rback-proxy container
  kubeRbacProxy:
    # resources to be allocated to the kube-rbac-proxy
    resources:
      limits:
        cpu: 500m
        memory: 128Mi
      requests:
        cpu: 5m
        memory: 64Mi
  # Set values for controller manager container
  manager:
    # resources to be allocated to the controller manager
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 10m
        memory: 64Mi
  # Set values for controller infraManager container
  infraManager:
    # resources to be allocated to the controller infraManager
    resources:
      limits:
        cpu: 500m
        memory: 128Mi
      requests:
        cpu: 10m
        memory: 64Mi
  # Set values for job scheduler container
  jobScheduler:
    resources:
      limits:
        cpu: 256m
        memory: 64Mi
      requests:
        cpu: 10m
        memory: 64Mi
    # Port number that should not conflict with another container in the same pod
    metricsBindAddress: 9090
    healthProbeBindAddress: 8082
    port: 9444
# Credentials to pull image from container registry.
imageCredentials:
  # Name of the secret containing the credentials to pull image from the container registry.
  imagePullSecretName: ndk-image-pull-secret
  # Image registry credentials
  # The credentials are used to create the image pull secret during helm install.
  # If the username is specified, the password and email must also be specified.
  # If the username is not specified, it is assumed the image pull secret already
  # exists in the cluster.
  credentials:
    registry: https://index.docker.io/v1/
    username: 
    password: 
    email: 
# Configuration to expose controller metrics service
metricsService:
  ports:
  - name: https
    port: 8443
    protocol: TCP
    targetPort: https
  type: ClusterIP
# Configuration to expose NDK's webhook service
webhookService:
  ports:
  - port: 443
    protocol: TCP
    targetPort: 9443
  type: ClusterIP
# Configuration to expose the grpc service.
intercomService:
  ports:
  - port: 2021
    protocol: TCP
    targetPort: 2021
  type: LoadBalancer
  # kube-vip  v0.2.1+ must be installed for this feature to work.
  # When set to true, kube-vip uses the local network DHCP to assign
  # LoadBalancer IP address to the intercom service. For dev/qa purposes only.
  useKubevipDhcp: false
  loadBalancerClass:
  loadBalancerIP:
# Configuration to expose job scheduler's webhook service
schedulerWebhookService:
  port: 9444
  protocol: TCP
  targetPort: 9444
  type: ClusterIP

tls:
  webhook:
    # AUTOGENERATED: autogenerated cert without cert-manager. A secret named with $(secretName) will be installed
    # SECRET: cert based on existing tls secret. $(secretName) will be used for cert check
    # ISSUER: cert based on existing cert-manager and issuer. Please provide $(issuerName) and $(secretName) pre-installed
    # SELF_SIGNED: cert based on existing cert-manager. Nothing needs to be configured if you choose this mode
    mode: "SELF_SIGNED"
    # Where to get the cert for the webhook. - "generate, secret"
    autogenerated:
      # Allow to renew self-signed generated certificate
      renew: false
      # Validity of certificate when generated by Helm
      validityDuration: 3650
    issuer:
      issuerName: ""
    # Name of the secret where certificate are stored
    # Should be a pre-existing secret in release namespace if tls.webhook.mode = SECRET
    secretName: webhook-server-cert
  server:
    # Enable TLS for the NDK server.
    # @default -- true
    enable: true
    # Enables mTLS for the NDK server.
    # Supports SECRET and ISSUER modes.
    enableMTLS: false
    # SECRET: cert based on existing tls secret. $(secretName) will be used for
    #  cert check. If tls.server.mode is 'SECRET', please provide 'clusterName'-
    #  which is the DNS name that has been used as SAN in the TLS certificate.
    # ISSUER: cert based on existing cert-manager and issuer.
    #  Please provide $(issuerName) and $(secretName) pre-installed.
    # SELF_SIGNED: cert based on existing cert-manager.
    #  Nothing needs to be configured if you choose this mode.
    # @default -- "SELF_SIGNED"
    mode: "SELF_SIGNED"
    # Issuer represents the certificate authority
    issuer:
      # Name of the certificate issuer.
      # If tls.server.mode is 'SELF_SIGNED', issuerName will be set to reflect
      # the selfsigned-issuer.
      issuerName: ""
    # Name of the secret where certificates are stored
    # If tls.server.mode is 'SECRET', secretName must match an existing secret
    # in the cluster.
    # @default -- "ndk-server-cert"
    secretName: ndk-server-cert
    # Location on the disk to mount the tls certificate key pair.
    # If enableMTLS is set to true, server ca certificate will be mounted at
    # "$certMountLocation/serverca".
    # Default will be used if no values are set.
    # @default -- "/etc/certs"
    certMountLocation: "/etc/certs"
    # Cluster name is the DNS name to be used as the subject alternative name (SAN)
    # in the TLS certificate.
    # If tls.server.mode is set to 'SECRET', the DNS subject alternative name (SAN)
    # already provided in the certificate secret will be used.
    clusterName:

# Configurable parameters for dataservices controllers
config:
  # To provide secret to be used by controllers for storage backend authentication
  # @Required-- secret should be in the helm release namespace
  secret:
    # pointer to the secret to be consumed by controllers
    name: ntnx-pc-secret
    # path to mount the secret as a volume
    dir:  "/var/run/ntnx-secret-dir"
  # Configurable parametrs for dataservices controller manager
  controllerManagerConfig:
    health:
      # HealthProbeBindAddress is the TCP address that the controller should bind to
      healthProbeBindAddress: ":8081"
    # LeaderElection config to be used when configuring the manager.Manager leader election
    leaderElection:
      leaderElect: true
      resourceName: d30ae773.nutanix.com
    metrics:
      # BindAddress is the TCP address that the controller should bind to
      bindAddress: 127.0.0.1:8080
    # defines the config for webhook server for the controller.
    webhook:
      # port is the port that the webhook server serves at.
      port: 9443
      # host is the hostname that the webhook server binds to.
      # @default -- ""
      host:
      # CertDir is the directory that contains the server key and certificate.
      # if not set, webhook server would look up the server key and certificate in
      # {TempDir}/k8s-webhook-server/serving-certs. The server key and certificate
      # must be named tls.key and tls.crt, respectively.
      certDir:
    flags:
      # Zap logger configuration:
      # Development Mode: encoder=consoleEncoder, logLevel=Debug, stackTraceLevel=Warn
      # Production Mode: encoder=jsonEncoder, logLevel=Info, stackTraceLevel=Error
      - "--zap-devel=false"  # Set to false for production mode (default)

      # Zap logger verbosity level:
      # Can be one of ‘debug’, ‘info’, ‘error’, or an integer > 0 for custom debug levels.
      # @default -- debug
      # - "--zap-log-level=debug"

      # Disable witness for storage recovery:
      # Provision to disable the witness, for example if deploying NDK on a setup where PC
      # runs on one of the PEs in sync rep.
      # - --disable-witness-for-storage-recovery
  infraManagerConfig:
    flags:
      # Example:
      # - "--requeue_interval=20"
  # Configuration of the Grpc server running in NDK.
  ndkServerConfig:
    # Port at which the grpc server in NDK listens.
    port: 2021
    # Enables or disables server reflection on the grpc server.
    enableServerReflection: true
